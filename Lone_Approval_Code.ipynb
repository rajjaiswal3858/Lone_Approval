{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac804958",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "     \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa69e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Training Dataset.csv')\n",
    "df.head()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a42816",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1079da2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dfef6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysing gender column\n",
    "df['Gender'].value_counts().plot(kind='pie', autopct=\"%1.1f%%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b6181b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gender vs loan_status\n",
    "df.groupby('Gender')['Loan_Status'].value_counts().plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3854b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Gender', hue='Loan_Status', data=df)\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Gender vs Loan Status')\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Loan Status')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0378d2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage of male & female in approved loans\n",
    "approved_loans = df[df['Loan_Status']=='Y']\n",
    "total_approved = len(approved_loans)\n",
    "total_males = len(df[df['Gender']=='Male'])\n",
    "total_females = len(df[df['Gender']=='Female'])\n",
    "approved_males = len(approved_loans[approved_loans['Gender']=='Male'])\n",
    "approved_females = len(approved_loans[approved_loans['Gender']=='Female'])\n",
    "\n",
    "print(f'Percentage of male with approved loans: {approved_males/total_males}')\n",
    "print(f'Percentage of female with approved loans: {approved_females/total_females}')\n",
    "print(f'Male loans approved: {approved_males/total_approved}')\n",
    "print(f'Female loans approved: {approved_females/total_approved}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a45bc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysing married column\n",
    "df['Married'].value_counts().plot(kind='pie', autopct='%1.1f%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c16d470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# married vs loan_status\n",
    "df.groupby('Married')['Loan_Status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe3ea9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Married', hue='Loan_Status', data=df)\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Married vs Loan Status')\n",
    "plt.xlabel('Married')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Loan Status')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924ef821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframe for approved loans\n",
    "approved_loans = df[df['Loan_Status'] == 'Y']\n",
    "\n",
    "#  the total number of approved loans\n",
    "total_approved = len(approved_loans)\n",
    "\n",
    "#  the number of approved loans for married and unmarried applicants\n",
    "unmarried_approved = approved_loans[approved_loans['Married'] == 'No']\n",
    "married_approved = approved_loans[approved_loans['Married'] == 'Yes']\n",
    "\n",
    "#  the percentages\n",
    "percent_married_approved = (len(married_approved) / total_approved) * 100\n",
    "percent_unmarried_approved = (len(unmarried_approved) / total_approved) * 100\n",
    "\n",
    "# the number of approved loans for married males and females\n",
    "married_males_approved = len(married_approved[married_approved['Gender'] == 'Male'])\n",
    "married_females_approved = len(married_approved[married_approved['Gender'] == 'Female'])\n",
    "\n",
    "# the total number of approved loans for males and females\n",
    "approved_males = len(approved_loans[approved_loans['Gender'] == 'Male'])\n",
    "approved_females = len(approved_loans[approved_loans['Gender'] == 'Female'])\n",
    "\n",
    "#  the percentages for married males and females\n",
    "percent_married_males_approved = (married_males_approved / approved_males) * 100\n",
    "percent_married_females_approved = (married_females_approved / approved_females) * 100\n",
    "\n",
    "print(f'Percentage of married approved loans: {percent_married_approved:.2f}%')\n",
    "print(f'Percentage of unmarried approved loans: {percent_unmarried_approved:.2f}%')\n",
    "print(f'Percentage of married males with approved loans: {percent_married_males_approved:.2f}%')\n",
    "print(f'Percentage of married females with approved loans: {percent_married_females_approved:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b3c4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysing dependents column\n",
    "df['Dependents'].value_counts().plot(kind='pie', autopct='%1.1f%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4e2055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependents vs loan_status\n",
    "# Calculate the counts of loan statuses grouped by dependents\n",
    "dependents_loan_status_counts = df.groupby('Dependents')['Loan_Status'].value_counts()\n",
    "\n",
    "# Convert the counts to a percentage\n",
    "dependents_loan_status_percentage = dependents_loan_status_counts.groupby(level=0, group_keys=False).apply(lambda x: 100 * x / float(x.sum()))\n",
    "\n",
    "# Display the percentage\n",
    "print(dependents_loan_status_percentage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47067ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#analysing education column\n",
    "df['Education'].value_counts().plot(kind='pie', autopct='%1.1f%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3bccb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# education vs loan_status\n",
    "df.groupby('Education')['Loan_Status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27805c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count graduate and non-graduate approved loans\n",
    "graduate_approved = (approved_loans['Education'] == 'Graduate').sum()\n",
    "total_graduated = (df['Education']=='Graduate').sum()\n",
    "total_not_graduated = (df['Education']=='Not Graduate').sum()\n",
    "not_graduate_approved = (approved_loans['Education'] == 'Not Graduate').sum()\n",
    "\n",
    "# Total approved loans\n",
    "total_approved = len(approved_loans)\n",
    "\n",
    "# Calculate percentages\n",
    "print(f'Percentage of graduate loan approved: {graduate_approved / total_approved * 100:.2f}%')\n",
    "print(f'Percentage of not graduate loan approved: {not_graduate_approved / total_approved * 100:.2f}%')\n",
    "print(f'Percentage of graduate approval chances: {graduate_approved/total_graduated * 100:.2f}%')\n",
    "print(f'Percentage of not graduate approval chances: {not_graduate_approved/total_not_graduated * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f79b900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysing self employed column\n",
    "df['Self_Employed'].value_counts().plot(kind='pie', autopct='%1.1f%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237a95e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# self employed vs loan_status\n",
    "df.groupby('Self_Employed')['Loan_Status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffab338",
   "metadata": {},
   "outputs": [],
   "source": [
    "self_employed_approved = (approved_loans['Self_Employed']=='Yes').sum()\n",
    "not_self_employed_approved = (approved_loans['Self_Employed']=='No').sum()\n",
    "self_employed = (df['Self_Employed']=='Yes').sum()\n",
    "not_self_employed = (df['Self_Employed']=='No').sum()\n",
    "\n",
    "print(f'Percentage of self employed approved loans: {self_employed_approved/total_approved*100:.2f}%')\n",
    "print(f'Percentage of not self employed approved loans: {not_self_employed_approved/total_approved*100:.2f}%')\n",
    "print(f'Self employed approval chances: {self_employed_approved/self_employed*100:.2f}%')\n",
    "print(f'Not Self employed approval chances: {not_self_employed_approved/not_self_employed*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45269f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysing ApplicantIncome column\n",
    "df['ApplicantIncome'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949f19bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['ApplicantIncome'], kde=True)\n",
    "plt.title('Distribution of Applicant Income')\n",
    "plt.xlabel('Applicant Income')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(df['ApplicantIncome'])\n",
    "plt.title('Box Plot of Applicant Income')\n",
    "plt.xlabel('Applicant Income')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362469fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df['ApplicantIncome'].quantile(0.25)\n",
    "Q3 = df['ApplicantIncome'].quantile(0.75)\n",
    "IQR = Q1 - Q3\n",
    "\n",
    "# Define bounds\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Outliers\n",
    "outliers = df[(df['ApplicantIncome'] < lower_bound) | (df['ApplicantIncome'] > upper_bound)]\n",
    "print(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf25bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop loan_id column\n",
    "df.drop('Loan_ID', axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5319c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysing coapplicant income\n",
    "df['CoapplicantIncome'].describe()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffc91f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['CoapplicantIncome'], kde=True)\n",
    "plt.title('Distribution of CoApplicant Income')\n",
    "plt.xlabel('Applicant Income')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(df['CoapplicantIncome'])\n",
    "plt.title('Box Plot of CoApplicant Income')\n",
    "plt.xlabel('Applicant Income')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8d3dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysing loan amount\n",
    "# Fill missing values in LoanAmount with the median value\n",
    "df['LoanAmount'].fillna(df['LoanAmount'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe12343",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LoanAmount'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd42ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histplot of Loan Amount\n",
    "sns.histplot(x=df['LoanAmount'], kde=True)\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(x=df['LoanAmount'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43599e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Loan_Amount_Term'].fillna(df['Loan_Amount_Term'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59b7fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Loan_Amount_Term'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b58ae78",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='Loan_Amount_Term', data=df)\n",
    "plt.title('Count Plot of Loan Amount Term')\n",
    "plt.xlabel('Loan Amount Term')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc58578",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='Loan_Amount_Term', hue='Loan_Status', data=df)\n",
    "plt.title('Loan Status vs Loan Amount Term')\n",
    "plt.xlabel('Loan Amount Term')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Loan Status')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e0c718",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Credit_History'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d99bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Credit_History'].fillna(1.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d7ce7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# credit history vs loan status\n",
    "df.groupby('Credit_History')['Loan_Status'].value_counts()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ffd705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter approved loans\n",
    "approved_loans = df[df['Loan_Status'] == 'Y']\n",
    "\n",
    "# Calculate the counts for Credit_History\n",
    "credit_history_1 = (df['Credit_History'] == 1.0).sum()\n",
    "credit_history_0 = (df['Credit_History'] == 0.0).sum()\n",
    "\n",
    "# Calculate the counts for approved loans with respective Credit_History\n",
    "credit_1_approved = (approved_loans['Credit_History'] == 1.0).sum()\n",
    "credit_0_approved = (approved_loans['Credit_History'] == 0.0).sum()\n",
    "\n",
    "# Print the chances of loan approval\n",
    "print(f'Loan approval chances with credit history: {credit_1_approved / credit_history_1 * 100:.2f}%')\n",
    "print(f'Loan approval chances without credit history: {credit_0_approved / credit_history_0 * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dcab78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysing property area column\n",
    "df['Property_Area'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04526771",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Property_Area')['Loan_Status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374552bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rural = (df['Property_Area']=='Rural').sum()\n",
    "semiurban = (df['Property_Area']=='Semiurban').sum()\n",
    "urban = (df['Property_Area']=='Urban').sum()\n",
    "\n",
    "rural_approved = (approved_loans['Property_Area']=='Rural').sum()\n",
    "semiurban_approved = (approved_loans['Property_Area']=='Semiurban').sum()\n",
    "urban_approved = (approved_loans['Property_Area']=='Urban').sum()\n",
    "\n",
    "print(f'Percentage of rural approved: {rural_approved/rural*100:.2f}%')\n",
    "print(f'Percentage of semiurban approved: {semiurban_approved/semiurban*100:.2f}%')\n",
    "print(f'Percentage of rural approved: {urban_approved/urban*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7235175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation matrix\n",
    "# Selecting numeric columns for correlation calculation\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Label encoding for non-numeric columns\n",
    "label_encoder = LabelEncoder()\n",
    "for column in df.columns:\n",
    "    if df[column].dtype == 'object':\n",
    "        df[column] = label_encoder.fit_transform(df[column].astype(str))\n",
    "\n",
    "# Display encoded DataFrame\n",
    "print(\"\\nEncoded DataFrame:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcc3774",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mat = df.corr()\n",
    "sns.heatmap(corr_mat, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n",
    "plt.figure(figsize=(10,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b75e310",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Loan_Status', axis=1)\n",
    "y = df['Loan_Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb48d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting into train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dce64ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc_model = RandomForestClassifier()\n",
    "rfc_model.fit(X_train, y_train)\n",
    "\n",
    "rfc_ypred = rfc_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9d362c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lg_model = LogisticRegression()\n",
    "lg_model.fit(X_train, y_train)\n",
    "lg_ypred = lg_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6673517b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Assuming you have already trained your model and made predictions\n",
    "# lg_model.fit(X_train, y_train)\n",
    "# lg_ypred = lg_model.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression:\")\n",
    "print(f'Accuracy: {accuracy_score(y_test, lg_ypred):.2f}')\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, lg_ypred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, lg_ypred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb47cc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Logistic Regression:\")\n",
    "print(f'Accuracy: {accuracy_score(y_test, lg_ypred)}')\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, lg_ypred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, lg_ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4fe053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using xgboost\n",
    "!pip install xgboost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_model = XGBClassifier()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_ypred = xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06002189",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale/normalize the data\n",
    "scaler = StandardScaler()\n",
    "df[['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term']] = scaler.fit_transform(\n",
    "    df[['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term']]\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd0ba36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc_model = RandomForestClassifier()\n",
    "rfc_model.fit(X_train, y_train)\n",
    "\n",
    "rfc_ypred = rfc_model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Random Forest Evaluation\n",
    "print(\"\\nRandom Forest Classifier:\")\n",
    "print(f'Accuracy: {accuracy_score(y_test, rfc_ypred)}')\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, rfc_ypred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, rfc_ypred))\n",
    "\n",
    "# logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lg_model = LogisticRegression()\n",
    "lg_model.fit(X_train, y_train)\n",
    "lg_ypred = lg_model.predict(X_test)\n",
    "\n",
    "# Logistic Regression Evaluation\n",
    "print(\"Logistic Regression:\")\n",
    "print(f'Accuracy: {accuracy_score(y_test, lg_ypred)}')\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, lg_ypred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, lg_ypred))\n",
    "\n",
    "# using xgboost\n",
    "!pip install xgboost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_model = XGBClassifier()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_ypred = xgb_model.predict(X_test)\n",
    "\n",
    "# Xgboost Evaluation\n",
    "print(\"xgboost:\")\n",
    "print(f'Accuracy: {accuracy_score(y_test, xgb_ypred)}')\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, xgb_ypred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, xgb_ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d74d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Hyperparameter tuning for Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "grid_search_rf = GridSearchCV(estimator=rfc_model, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best Parameters: {grid_search_rf.best_params_}\")\n",
    "best_rf = grid_search_rf.best_estimator_\n",
    "y_pred_best_rf = best_rf.predict(X_test)\n",
    "\n",
    "print(\"\\nTuned Random Forest Classifier:\")\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred_best_rf)}')\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_best_rf))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_best_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f894879f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Feature importance for Random Forest\n",
    "importances = rfc_model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=importances[indices], y=X.columns[indices])\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.show()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d642f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "ConfusionMatrixDisplay.from_estimator(rfc_model,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d604b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_data = pd.read_csv('Test Dataset.csv')\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b0dd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data for demonstration\n",
    "data = {\n",
    "    'Loan_ID': ['LP001015', 'LP001022', 'LP001031', 'LP001035', 'LP001051'],\n",
    "    'Gender': ['Male', 'Male', 'Male', 'Male', 'Male'],\n",
    "    'Married': ['Yes', 'Yes', 'Yes', 'Yes', 'No'],\n",
    "    'Dependents': ['0', '1', '2', '2', '0'],\n",
    "    'Education': ['Graduate', 'Graduate', 'Graduate', 'Graduate', 'Not Graduate'],\n",
    "    'Self_Employed': ['No', 'No', 'No', 'No', 'No'],\n",
    "    'ApplicantIncome': [5720, 3076, 5000, 2340, 3276],\n",
    "    'CoapplicantIncome': [0, 1500, 1800, 2546, 0],\n",
    "    'LoanAmount': [110.0, 126.0, 208.0, 100.0, 78.0],\n",
    "    'Loan_Amount_Term': [360.0, 360.0, 360.0, 360.0, 360.0],\n",
    "    'Credit_History': [1.0, 1.0, 1.0, float('nan'), 1.0],\n",
    "    'Property_Area': ['Urban', 'Urban', 'Urban', 'Urban', 'Urban']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Preprocess the test data similar to the training data\n",
    "df['Dependents'].replace('3+', 3, inplace=True)\n",
    "df['LoanAmount'].fillna(df['LoanAmount'].median(), inplace=True)\n",
    "df['Loan_Amount_Term'].fillna(df['Loan_Amount_Term'].median(), inplace=True)\n",
    "df['Credit_History'].fillna(df['Credit_History'].median(), inplace=True)\n",
    "\n",
    "# Encode categorical variables\n",
    "df = pd.get_dummies(df)\n",
    "\n",
    "# Ensure the same order of columns as the training data (assuming X is your training dataframe)\n",
    "missing_cols = set(X.columns) - set(df.columns)\n",
    "for col in missing_cols:\n",
    "    df[col] = 0\n",
    "df = df[X.columns]\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c9a3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preprocess the test data similar to the training data\n",
    "test_data['Dependents'].replace('3+', 3, inplace=True)\n",
    "test_data['LoanAmount'].fillna(test_data['LoanAmount'].median(), inplace=True)\n",
    "test_data['Loan_Amount_Term'].fillna(test_data['Loan_Amount_Term'].median(), inplace=True)\n",
    "test_data['Credit_History'].fillna(test_data['Credit_History'].median(), inplace=True)\n",
    "\n",
    "# Encode categorical variables\n",
    "test_data = pd.get_dummies(test_data)\n",
    "\n",
    "# Ensure the same order of columns as the training data\n",
    "missing_cols = set(X.columns) - set(test_data.columns)\n",
    "for col in missing_cols:\n",
    "    test_data[col] = 0\n",
    "test_data = test_data[X.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ebcaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Scale the test data\n",
    "test_data[['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term']] = scaler.transform(\n",
    "    test_data[['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term']]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2c0a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make predictions\n",
    "test_predictions = best_rf.predict(test_data)\n",
    "\n",
    "test = pd.read_csv('Test Dataset.csv')\n",
    "\n",
    "# Prepare the submission file\n",
    "submission = pd.DataFrame({\n",
    "    'Loan_ID': test['Loan_ID'],\n",
    "    'Loan_Status': test_predictions\n",
    "})\n",
    "\n",
    "# Convert numerical predictions to categorical ('Y' or 'N')\n",
    "submission['Loan_Status'] = submission['Loan_Status'].map({1: 'Y', 0: 'N'})\n",
    "\n",
    "# Save the submission file\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "# Display the submission file\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e6f7c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
